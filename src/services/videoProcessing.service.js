import { v4 as uuidv4 } from 'uuid';
import path from 'path';
import { getVideoMetadata } from '../utils/ffmpeg.utils.js';
import { detectShotBoundaries } from './shotDetection.service.js';
import { extractKeyframes } from './keyframe.service.js';
import { analyzeKeyframesSemantics } from './visionAnalysis.service.js';
import { analyzeRhythm } from './rhythmAnalysis.service.js';
import { buildSceneSpec, exportSceneSpec } from './sceneBuilder.service.js';

const SPECS_DIR = process.env.STORAGE_DIR
    ? path.join(process.env.STORAGE_DIR, 'specs')
    : './storage/specs';

import fs from 'fs/promises';
await fs.mkdir(SPECS_DIR, { recursive: true });

/**
 * å®Œæ•´çš„å½±ç‰‡è™•ç†æµç¨‹
 * @param {string} videoPath - å½±ç‰‡è·¯å¾‘
 * @returns {Promise<Object>} - è™•ç†çµæœ
 */
export const processVideo = async (videoPath) => {
    const videoId = uuidv4();

    // ç¢ºä¿ä½¿ç”¨çµ•å°è·¯å¾‘
    const absoluteVideoPath = path.isAbsolute(videoPath)
        ? videoPath
        : path.resolve(videoPath);

    console.log(`\nğŸ¬ Starting video processing: ${videoId}`);
    console.log(`ğŸ“ Video path: ${absoluteVideoPath}\n`);

    try {
        // ===== æ­¥é©Ÿ 1: æå–å½±ç‰‡å…ƒæ•¸æ“š =====
        console.log('ğŸ“Š Step 1/6: Extracting video metadata...');
        const metadata = await getVideoMetadata(absoluteVideoPath);
        metadata.videoId = videoId;
        console.log(`âœ… Duration: ${metadata.duration}s, Resolution: ${metadata.width}x${metadata.height}, FPS: ${metadata.fps}\n`);

        // ===== æ­¥é©Ÿ 2: åˆ†é¡æª¢æ¸¬ =====
        console.log('ğŸï¸  Step 2/6: Detecting shot boundaries...');
        const shots = await detectShotBoundaries(absoluteVideoPath);
        console.log(`âœ… Detected ${shots.length} shots\n`);

        // ===== æ­¥é©Ÿ 3: æå–é—œéµå¹€ =====
        console.log('ğŸ–¼ï¸  Step 3/6: Extracting keyframes...');
        const keyframes = await extractKeyframes(absoluteVideoPath, shots, videoId);
        console.log(`âœ… Extracted ${keyframes.length} keyframes\n`);

        // ===== æ­¥é©Ÿ 4: è¦–è¦ºèªç¾©åˆ†æ =====
        console.log('ğŸ” Step 4/6: Analyzing visual semantics...');
        const semantics = await analyzeKeyframesSemantics(keyframes);
        console.log(`âœ… Analyzed ${semantics.length} frames\n`);

        // ===== æ­¥é©Ÿ 5: ç¯€å¥åˆ†æ =====
        console.log('ğŸµ Step 5/6: Analyzing rhythm and audio...');
        const rhythm = await analyzeRhythm(absoluteVideoPath, videoId, shots);
        console.log(`âœ… Energy curve: ${rhythm.energy_curve}, Cut frequency: ${rhythm.cut_frequency.toFixed(2)}/s\n`);

        // ===== æ­¥é©Ÿ 6: æ§‹å»º Scene Spec =====
        console.log('ğŸ—ï¸  Step 6/6: Building scene specification...');
        const sceneSpec = buildSceneSpec(metadata, shots, semantics, rhythm);

        // å°å‡º JSON
        const specPath = path.join(SPECS_DIR, `${videoId}.json`);
        await exportSceneSpec(sceneSpec, specPath);

        console.log(`\nâœ¨ Processing complete!`);
        console.log(`ğŸ“„ Scene spec: ${specPath}\n`);

        // ===== æ­¥é©Ÿ 7: è‡ªå‹•ç”Ÿæˆ Veo Prompts =====
        console.log('ğŸ“ Step 7/7: Generating Veo prompts...');
        const { generateVeoPrompts, saveVeoPrompts } = await import('./videoGeneration.service.js');
        const veoPrompts = generateVeoPrompts(sceneSpec);

        // ä¿å­˜ prompts
        const PROMPTS_DIR = process.env.STORAGE_DIR
            ? path.join(process.env.STORAGE_DIR, 'veo-prompts')
            : './storage/veo-prompts';
        await fs.mkdir(PROMPTS_DIR, { recursive: true });
        const promptsPath = path.join(PROMPTS_DIR, `${videoId}-prompts.json`);
        await saveVeoPrompts(veoPrompts, promptsPath);

        console.log(`âœ… Generated ${veoPrompts.prompts.length} Veo prompts\n`);

        return {
            success: true,
            videoId,
            sceneSpec,
            specPath,
            veoPrompts,  // æ·»åŠ  prompts åˆ°å›æ‡‰
            promptsPath,
            stats: {
                totalShots: shots.length,
                totalDuration: metadata.duration,
                avgShotLength: sceneSpec.avg_shot_length,
                keyframesExtracted: keyframes.length,
                veoPromptsGenerated: veoPrompts.prompts.length
            }
        };

    } catch (error) {
        console.error(`âŒ Processing failed: ${error.message}`);
        throw error;
    }
};

/**
 * ç²å–å·²è™•ç†çš„å½±ç‰‡è¦æ ¼
 * @param {string} videoId - å½±ç‰‡ ID
 * @returns {Promise<Object>} - Scene Spec
 */
export const getSceneSpec = async (videoId) => {
    const specPath = path.join(SPECS_DIR, `${videoId}.json`);
    const content = await fs.readFile(specPath, 'utf-8');
    return JSON.parse(content);
};

/**
 * åˆ—å‡ºæ‰€æœ‰å·²è™•ç†çš„å½±ç‰‡
 * @returns {Promise<Array>} - å½±ç‰‡åˆ—è¡¨
 */
export const listProcessedVideos = async () => {
    const files = await fs.readdir(SPECS_DIR);
    const specs = [];

    for (const file of files) {
        if (file.endsWith('.json')) {
            const content = await fs.readFile(path.join(SPECS_DIR, file), 'utf-8');
            const spec = JSON.parse(content);
            specs.push({
                videoId: spec.video_id,
                duration: spec.total_duration,
                shots: spec.total_shots,
                generatedAt: spec.generated_at
            });
        }
    }

    return specs;
};
